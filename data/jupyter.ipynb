{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scientific and Research Publishing on Digital Platforms\n",
    "#### Data Ingest and Processing\n",
    "\n",
    "August 10, 2019\n",
    "\n",
    "## Importing Modules and Defining Custom Functions\n",
    "For this project, I chose to use the Python requests modules to interact with Zenodo's website and BeautifulSoup and Pandas to parse and manipulate data. I used SQLAlchemy to interact with a local database where I stored intermediate results from the website mining.\n",
    "\n",
    "I also used GeoPy to find locations and their coordinates, cities and countries associated with research institutions using the free Nominatim geocoder primarily against Open Street Map (OSM) with Google's geocoder API as a backup. I defined two custom functions to handle geocoding for these services, and use the Folium library to review the locations on a map before exporting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       " if (code_show){\n",
       " $('div.input').hide();\n",
       " } else {\n",
       " $('div.input').show();\n",
       " }\n",
       " code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import required modules\n",
    "import sys\n",
    "sys.path.append(\"../\") # go to parent dir\n",
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "from geopy.geocoders import Nominatim\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import display, HTML, clear_output, FileLink\n",
    "from sqlalchemy import create_engine\n",
    "from datetime import datetime, date, timedelta\n",
    "import folium as folium\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.geocoders import GoogleV3\n",
    "\n",
    "# Demo flag. Set to False to run through all data\n",
    "demo=True\n",
    "\n",
    "# Define useragent and API key for location lookups. Do not leave in final code\n",
    "gkey = API_KEY\n",
    "ua = USER_AGENT\n",
    "\n",
    "# Hides code in HTML output\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "code_folding": [
     1,
     14,
     37,
     62
    ]
   },
   "outputs": [],
   "source": [
    "# Define function to expand dataframe into new rows based on multi-value columns\n",
    "def explode(df,col,delimiter=','):\n",
    "    df = df.copy()\n",
    "    cols1 = list(df.columns)\n",
    "    cols2 = cols1.copy()\n",
    "    cols2.remove(col)\n",
    "    df[col] = df[col].apply(lambda x: x.split(delimiter))\n",
    "    df = df[col].apply(pd.Series)\\\n",
    "        .merge(df, right_index = True, left_index = True)\\\n",
    "        .drop([col], axis = 1).melt(id_vars=cols2, value_name=col).drop(['variable'], axis = 1)\n",
    "    df = df[cols1]\n",
    "    return df\n",
    "\n",
    "# Define function to search OSM geocode API for location string\n",
    "def osm_geocode(location, geocoder):\n",
    "    # build blank results dictionary\n",
    "    result = {}\n",
    "    result['name'] = location\n",
    "    result['rawloc'] = ''\n",
    "    result['latitude'] = ''\n",
    "    result['longitude'] = ''\n",
    "    result['country'] = ''\n",
    "    result['city'] = ''\n",
    "    # Send request to geocode API\n",
    "    result['rawloc'] = geocoder.geocode(location, exactly_one=True,addressdetails=True)\n",
    "    try:\n",
    "        # Extract relevant fields from API response into results dictionary\n",
    "        result['latitude'] = result['rawloc'].latitude\n",
    "        result['longitude'] = result['rawloc'].longitude\n",
    "        result['country'] = result['rawloc'].raw['address']['country_code'].upper()\n",
    "        result['city'] = result['rawloc'].raw['address']['city']\n",
    "    except:\n",
    "        pass\n",
    "    # Output result dictionary from function\n",
    "    return(result)\n",
    "\n",
    "# Define function to search OSM geocode API for location string\n",
    "def google_geocode(location, geocoder):\n",
    "    # build blank results dictionary\n",
    "    result = {}\n",
    "    result['name'] = location\n",
    "    result['rawloc'] = ''\n",
    "    result['latitude'] = ''\n",
    "    result['longitude'] = ''\n",
    "    result['country'] = ''\n",
    "    result['city'] = ''\n",
    "    # Send request to geocode API\n",
    "    result['rawloc'] = geocoder.geocode(location, exactly_one=True)\n",
    "    try:\n",
    "        # Extract relevant fields from API response into results dictionary\n",
    "        result['latitude'] = result['rawloc'].latitude\n",
    "        result['longitude'] = result['rawloc'].longitude\n",
    "        expectedResult = [d for d in result['rawloc'].raw['address_components'] if d['types'] == ['country', 'political']]\n",
    "        result['country'] = expectedResult[0]['short_name']\n",
    "        expectedResult = [d for d in result['rawloc'].raw['address_components'] if d['types'] == ['locality', 'political']]\n",
    "        result['city'] = expectedResult[0]['short_name']\n",
    "    except:\n",
    "        pass\n",
    "    # Output result dictionary from function\n",
    "    return(result)\n",
    "\n",
    "# Define function to extract data and store in SQLite DB\n",
    "def extract(records): \n",
    "    # Extract XML fields to dictionary\n",
    "    cdicts = []\n",
    "    for record in records:\n",
    "        cdict={}\n",
    "        try:cdict['identifier'] = record.identifier.text\n",
    "        except:pass\n",
    "        try:cdict['subject'] = '|'.join([x.text for x in record.subjects.findChildren()])\n",
    "        except:pass\n",
    "        try:cdict['creator'] = '|'.join([x.creatorname.text.strip() for x in record.creators.findChildren('creator')])\n",
    "        except:pass\n",
    "        try:cdict['affiliation'] = '|'.join([x.affiliation.text.strip() for x in record.creators.findChildren('creator')])\n",
    "        except:pass\n",
    "        try:cdict['datestamp'] = record.datestamp.text\n",
    "        except:pass\n",
    "        try:cdict['issued'] = record.date.text\n",
    "        except:pass\n",
    "        try:cdict['title'] = record.title.text\n",
    "        except:pass\n",
    "        try:cdict['description'] = record.descriptions.text[:1000].strip()\n",
    "        except:pass\n",
    "        try:cdict['resourcetype'] = record.resourcetype.text.strip()\n",
    "        except:pass\n",
    "        try:cdict['resourcetypegeneral'] = record.resourcetype['resourcetypegeneral']\n",
    "        except:pass\n",
    "        try:cdict['setspec'] = record.setspec.text\n",
    "        except:pass\n",
    "        cdicts += [cdict]\n",
    "        # Convert dictionaries to dataframe\n",
    "        df = pd.DataFrame([cdict]).fillna('')\n",
    "        # Store found libraries in SQL database\n",
    "        engine=create_engine(sqlpath, echo=False)\n",
    "        try:df.to_sql(\"zenodo\", engine, if_exists=\"append\", index=False)\n",
    "        except:pass\n",
    "    return cdicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define template and build new local SQLite database\n",
    "if demo == True:\n",
    "    sqlpath = 'sqlite:///zenodo_demo.db'\n",
    "else:\n",
    "    sqlpath = 'sqlite:///zenodo.db'\n",
    "\n",
    "df = pd.DataFrame(columns=['identifier', 'subject', 'creator', 'affiliation', 'datestamp', 'issued',\n",
    "                          'title', 'description', 'resourceType', 'resourceTypeGeneral', 'setSpec'])\n",
    "engine=create_engine(sqlpath, echo=False)\n",
    "df.to_sql(\"zenodo\", engine, if_exists=\"replace\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mining Open Publication Records Through the Zenodo OAI Interface\n",
    "Zenodo provides open access through an Open Archives Initiative (AOI) XML interface which allows for retrieving structured metadata about publications. I authored a Python function to query the AOI interface for all data, and implemented a technique to query records by date. Even with splitting up the queries into individual days, the AOI interface only returns 100 records at a time. To get additional records I had to add a feature to the script to pull the temporary access token for each query, which changes after each additional 100 records and expires after 2 minutes. As the function looped through each XML response, it extracted key elements for my analysis and added it to a local SQLite database. Going back through the database, I was able to retrieve metadata for 865,366 publications over the course of two years. Pulling this data took multiple days due to rate limiting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-10\n",
      "https://zenodo.org/oai2d?verb=ListRecords&metadataPrefix=oai_datacite&from=2019-08-10T00:00:00Z&until=2019-08-10T23:59:59Z\n",
      "794 total results in database\n",
      "100 results retrieved. 100 / 794 (12.6%) results retrieved total\n",
      "2019-08-10:0: .eJxV...y4YWA\n",
      "Retrieving at 2019-08-12T21:09:03Z. Token expires 2019-08-12T21:10:58Z\n",
      "100 results retrieved. 200 / 794 (25.2%) results retrieved total\n",
      "2019-08-10:1: .eJwV...nUCYs\n",
      "Retrieving at 2019-08-12T21:09:09Z. Token expires 2019-08-12T21:11:03Z\n",
      "100 results retrieved. 300 / 794 (37.8%) results retrieved total\n",
      "2019-08-10:2: .eJwV...HgFxk\n",
      "Retrieving at 2019-08-12T21:09:14Z. Token expires 2019-08-12T21:11:09Z\n",
      "100 results retrieved. 400 / 794 (50.4%) results retrieved total\n",
      "2019-08-10:3: .eJwV...57fzk\n",
      "Retrieving at 2019-08-12T21:09:20Z. Token expires 2019-08-12T21:11:15Z\n",
      "100 results retrieved. 500 / 794 (63.0%) results retrieved total\n",
      "2019-08-10:4: .eJwV...LDZQw\n",
      "Retrieving at 2019-08-12T21:09:25Z. Token expires 2019-08-12T21:11:20Z\n",
      "100 results retrieved. 600 / 794 (75.6%) results retrieved total\n",
      "2019-08-10:5: .eJwV...DDN14\n",
      "Retrieving at 2019-08-12T21:09:31Z. Token expires 2019-08-12T21:11:26Z\n",
      "100 results retrieved. 700 / 794 (88.2%) results retrieved total\n",
      "2019-08-10:6: .eJwV...0EngA\n",
      "Retrieving at 2019-08-12T21:09:37Z. Token expires 2019-08-12T21:11:32Z\n",
      "94 results retrieved. 794 / 794 (100.0%) results retrieved total\n",
      "Script complete. 794 results retrieved total.\n"
     ]
    }
   ],
   "source": [
    "# Define start date and time delta range\n",
    "sdate = date(2019,8,10)\n",
    "daycount = 5\n",
    "\n",
    "if demo==True:\n",
    "    daycount=1\n",
    "\n",
    "daydelta = timedelta(days=-1)\n",
    "arcount = 0 \n",
    "# Loop through start date plus each day count in delta range\n",
    "for daynum in range(0,daycount):\n",
    "    # Build date string and Zenodo OAI search URL\n",
    "    daystring = (sdate + daydelta * daynum).strftime(\"%Y-%m-%d\")\n",
    "    print(daystring)\n",
    "    search_url = 'https://zenodo.org/oai2d?verb=ListRecords&metadataPrefix=oai_datacite&from=' + \\\n",
    "                            daystring + 'T00:00:00Z&until=' + daystring + 'T23:59:59Z'\n",
    "    print(search_url)\n",
    "    # Send request to page, retrieve content as XML, and parse into object tree with BeautifulSoup\n",
    "    xml_data = requests.get(search_url).content\n",
    "    soup = BeautifulSoup(xml_data)\n",
    "    records = soup.find_all(\"record\")\n",
    "    # Use function to extract data and store in SQLite DB\n",
    "    extract(records)\n",
    "    # Find total record count from OAI response\n",
    "    try:recsize = int(soup.resumptiontoken['completelistsize'])\n",
    "    except:recsize = len(records)\n",
    "    try:print(soup.resumptiontoken['completelistsize'] + ' total results in database')\n",
    "    except:pass\n",
    "    rcount = len(records)\n",
    "    try:print(str(len(records)) + ' results retrieved. ' + str(rcount) + ' / ' \n",
    "          + str(recsize) + ' (' + str(round(rcount/recsize*100, 1)) + '%) results retrieved total')\n",
    "    except:print(str(len(records)) + ' results retrieved. ' + str(rcount) + ' / ' \n",
    "          + str(recsize) + '  results retrieved total')\n",
    "    # Iterate over additional resumption tokens to get rest of data from search\n",
    "    for x in range(0,500000):\n",
    "        time.sleep(2)\n",
    "        try:\n",
    "            # Get token from current page\n",
    "            resumptiontoken = soup.resumptiontoken.text\n",
    "            if resumptiontoken == '': # Exit loop if there are no more tokens\n",
    "                break\n",
    "            print(daystring + ':' + str(x) + ': ' + resumptiontoken[:5] + '...' + resumptiontoken[-5:])\n",
    "            print('Retrieving at ' + datetime.utcnow().strftime(\"%Y-%m-%dT%H:%M:%SZ\") + \\\n",
    "                  '. Token expires ' + soup.resumptiontoken['expirationdate'])\n",
    "            # Send request to page, retrieve content as XML, and parse into object tree with BeautifulSoup\n",
    "            xml_data = requests.get('https://zenodo.org/oai2d?verb=ListRecords&resumptionToken=' \n",
    "                                    + resumptiontoken).content\n",
    "            soup = BeautifulSoup(xml_data)\n",
    "            records = soup.find_all(\"record\")\n",
    "            if len(records) == 0:\n",
    "                print('retrying')\n",
    "                # Send request to page, retrieve content as XML, and parse into object tree with BeautifulSoup\n",
    "                xml_data = requests.get('https://zenodo.org/oai2d?verb=ListRecords&resumptionToken=' \n",
    "                                        + resumptiontoken).content\n",
    "                soup = BeautifulSoup(xml_data)\n",
    "                records = soup.find_all(\"record\")\n",
    "            # Use function to extract data and store in SQLite DB\n",
    "            extract(records)\n",
    "            rcount += len(records)\n",
    "            print(str(len(records)) + ' results retrieved. ' + str(rcount) + ' / ' \n",
    "              + str(recsize) + ' (' + str(round(rcount/recsize*100, 1)) + '%) results retrieved total')\n",
    "        except: # Exit loop if there are no more tokens\n",
    "            break\n",
    "    arcount += rcount\n",
    "    \n",
    "print('Script complete. ' + str(arcount) + ' results retrieved total.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing and Aggregating Data From Results\n",
    "As a preliminary data exploratory analysis, I used custom SQL queries to pull data into a Pandas dataframe in Jupyter and looked for outliers and trends. I noted that resourceType’s and resourceTypeGeneral mapped together and that some types of resources may inflate statistics, such as image figures, which each receive their own DOI number in many cases. Also, in looking at affiliations I noted some non-academic organizations with obviously inflated publication numbers. For the visualization piece, I will limit the final rollups to a limited number of established academic institutions. I also needed to do similar filtering and curation of publication subjects and remove any invalid date of issue, as some dates were in the future.\n",
    "\n",
    "### Record Types\n",
    "I began with an aggregation of record types. To get the aggregations I needed, I used a direct SQL group query against the local Zenodo database with month, resource type, resource type (general), and produced a by month record count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95 month/category aggregated rows created.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>resourceTypeGeneral</th>\n",
       "      <th>resourceType</th>\n",
       "      <th>records</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-07</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-07</td>\n",
       "      <td>Software</td>\n",
       "      <td>Software</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-07</td>\n",
       "      <td>Text</td>\n",
       "      <td>Book</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-07</td>\n",
       "      <td>Text</td>\n",
       "      <td>Book section</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-07</td>\n",
       "      <td>Text</td>\n",
       "      <td>Conference paper</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Query local database for aggregated Zenodo publication data\n",
    "engine = create_engine(sqlpath, echo=False)\n",
    "df = pd.read_sql_query(\n",
    "    'SELECT SUBSTR(issued,1,7) AS month, resourceTypeGeneral, resourceType, COUNT(*) AS \\\n",
    "    records FROM (SELECT DISTINCT identifier, resourceTypeGeneral, resourceType, issued FROM zenodo \\\n",
    "    WHERE issued >= \"2001-01\" AND issued < \"2019-08\") \\\n",
    "    GROUP BY SUBSTR(issued,1,7), resourceTypeGeneral, resourceType ORDER BY month DESC;'\n",
    "    , engine).fillna('') # This SQL query aggregates all publications by month and category based on unique DOI\n",
    "\n",
    "# Format record counts as integers\n",
    "df = df.astype({\"records\": int})\n",
    "\n",
    "# Fill blank resourceType\n",
    "df['resourceType'] = \\\n",
    "    df['resourceType'].where(\n",
    "        df['resourceType'] !='', df['resourceTypeGeneral'])\n",
    "\n",
    "print(str(len(df)) + ' month/category aggregated rows created.')\n",
    "display(HTML(df.head().to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this by month aggregation, my next step was to generate a running total for each month and each category, as well as an \"all\" summarization for each category, like all months' totals for a type or all types' totals for a month. Doing this in Python is better than push the summarization to the JavaScript visualization stage since it only needs to be calculated once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>resourceTypeGeneral</th>\n",
       "      <th>resourceType</th>\n",
       "      <th>records</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>All</td>\n",
       "      <td>All</td>\n",
       "      <td>All</td>\n",
       "      <td>356</td>\n",
       "      <td>356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>2019-07</td>\n",
       "      <td>All</td>\n",
       "      <td>All</td>\n",
       "      <td>102</td>\n",
       "      <td>356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>2019-06</td>\n",
       "      <td>All</td>\n",
       "      <td>All</td>\n",
       "      <td>15</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>2019-05</td>\n",
       "      <td>All</td>\n",
       "      <td>All</td>\n",
       "      <td>9</td>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>2019-04</td>\n",
       "      <td>All</td>\n",
       "      <td>All</td>\n",
       "      <td>24</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       month resourceTypeGeneral resourceType  records  total\n",
       "765      All                 All          All      356    356\n",
       "754  2019-07                 All          All      102    356\n",
       "744  2019-06                 All          All       15    254\n",
       "735  2019-05                 All          All        9    239\n",
       "759  2019-04                 All          All       24    230"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find aggregated counts for each month from all resource categories\n",
    "dfg = df.groupby(['month']).agg({'records': ['sum']}).reset_index()\n",
    "dfg.columns = ['month','records']\n",
    "dfg['resourceTypeGeneral'] = 'All'\n",
    "dfg['resourceType'] = 'All'\n",
    "dfg = dfg[['month','resourceTypeGeneral','resourceType','records']]\n",
    "df = pd.concat([df, dfg], ignore_index=True)\n",
    "\n",
    "# Aggregate running totals for each category\n",
    "month_list = list(set(df['month'].tolist()))\n",
    "types_list = df[['resourceTypeGeneral','resourceType']].drop_duplicates().to_dict('records')\n",
    "df2 = pd.DataFrame(columns=['month', 'resourceTypeGeneral', 'resourceType', 'records', 'total'])\n",
    "for types in types_list:\n",
    "    for month in month_list:\n",
    "        total = df[(df['month'] <= month) & \n",
    "                  (df['resourceTypeGeneral'] == types['resourceTypeGeneral']) & \n",
    "                  (df['resourceType'] == types['resourceType'])]['records'].sum()\n",
    "        dfp2 = df[(df['month'] == month) & \n",
    "                  (df['resourceTypeGeneral'] == types['resourceTypeGeneral']) & \n",
    "                  (df['resourceType'] == types['resourceType'])].copy()\n",
    "        if len(dfp2) == 0:\n",
    "            dfp2 = pd.DataFrame([[month, types['resourceTypeGeneral'], types['resourceType'], 0]], \n",
    "                                columns=['month', 'resourceTypeGeneral', 'resourceType', 'records'])\n",
    "        dfp2['total'] = total\n",
    "        # Concatenated back to working Dataframe\n",
    "        df2 = pd.concat([df2, dfp2], ignore_index=True)\n",
    "df2 = df2.astype({\"records\": int,\"total\": int})\n",
    "\n",
    "# Find aggregated counts for all months from each categories\n",
    "dfg = df2.groupby(['resourceTypeGeneral','resourceType']).agg({'records': ['sum'],\n",
    "                                                               'total': ['max']}).reset_index()\n",
    "dfg.columns = ['resourceTypeGeneral','resourceType','records','total']\n",
    "dfg['month'] = 'All'\n",
    "dfg = dfg[['month','resourceTypeGeneral','resourceType','records','total']]\n",
    "# Concatenated back to working Dataframe\n",
    "df2 = pd.concat([df2, dfg], ignore_index=True)\n",
    "df2 = df2.sort_values(by='total', ascending=False)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the results were aggregated into a single DataFrame, I converted it to a CSV for final review and a JSON for upload to the web site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='resource_types.json' target='_blank'>resource_types.json</a><br>"
      ],
      "text/plain": [
       "C:\\Users\\epcar\\resource_types.json"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.to_csv('resource_types.csv',index=False)\n",
    "df2.to_json('resource_types.json',orient='records')\n",
    "FileLink('resource_types.csv')\n",
    "FileLink('resource_types.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Universities\n",
    "The second aggregation was affiliation, with a specific filter for Universities and Colleges. To get the aggregations I needed, I used a direct SQL group query against the local Zenodo database with month, creator, affiliation, day and month. Because a record in Zenodo has multiple affiliations, I needed to pull back the events individually and split them before aggregating them by month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creator</th>\n",
       "      <th>affiliation</th>\n",
       "      <th>month</th>\n",
       "      <th>issued</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ashraf Afifi</td>\n",
       "      <td>Taif University, Al-Hawiya</td>\n",
       "      <td>2019-07</td>\n",
       "      <td>2019-07-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Prima Wulandari|Ridho Bayu Yefterson</td>\n",
       "      <td>Universitas Negeri Padang|Universitas Negeri Padang</td>\n",
       "      <td>2019-07</td>\n",
       "      <td>2019-07-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rahmi Ramadhani, Ermayanti Astuti, Titin Setiawati</td>\n",
       "      <td>Universitas Potensi Utama</td>\n",
       "      <td>2019-07</td>\n",
       "      <td>2019-07-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Afsheenjinan, A.|De Silva, A. C.|Yasawardene, A.D.K.S.N.|Thayaparan, S.</td>\n",
       "      <td>University of Moratuwa|University of Moratuwa|Lady Ridgeway Hospital|University of Moratuwa</td>\n",
       "      <td>2019-07</td>\n",
       "      <td>2019-07-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jakšová, Patrícia|Ľuptáčik, Peter|Miklisová, Dana</td>\n",
       "      <td>P.J. Šafárik University, Košice, Slovakia|P.J. Šafárik University, Košice, Slovakia|Institute of Parasitology, Slovak Academy of Sciences, Košice, Slovakia</td>\n",
       "      <td>2019-07</td>\n",
       "      <td>2019-07-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Query local database for all university publications\n",
    "engine = create_engine(sqlpath, echo=False)\n",
    "df = pd.read_sql_query(\n",
    "    'SELECT DISTINCT creator, affiliation, SUBSTR(issued,1,7) as month, SUBSTR(issued,1,10) as issued FROM zenodo \\\n",
    "    WHERE issued >= \"2001-01\" AND issued < \"2019-08\" AND (affiliation LIKE \"%Universi%\" OR affiliation LIKE \"%College%\") \\\n",
    "    ORDER BY issued DESC;'\n",
    "    , engine).fillna('')\n",
    "\n",
    "print(len(df))\n",
    "display(HTML(df.head().to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the data was returned from the SQL query as a dataframe, I used the custom explode function to split the results. Because there are so many affiliations, I used another function to grab a list of just the top n Universities from the dataset, in this case 100 results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101 records in original dataframe.\n",
      "43 records in expanded/filtered dataframe.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>affiliation</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Wageningen University</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Universitas Ekasakti</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qatar University</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Universidad Nacional de Juliaca</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>University of Moratuwa</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101 records in original dataframe.\n",
      "43 records in expanded/filtered dataframe.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>affiliation</th>\n",
       "      <th>records</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-07</td>\n",
       "      <td>Winona State University</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-07</td>\n",
       "      <td>University Bordeaux 2 (EA 3677 et Centre Ren? Labusqui?re) Bordeaux</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-07</td>\n",
       "      <td>Taif University</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-07</td>\n",
       "      <td>South East European University</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-07</td>\n",
       "      <td>Shri Jagdishprasad Jhabarmal Tibrewala University</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Group by specified column and create sorted top n counts\n",
    "n = 100\n",
    "col = 'affiliation'\n",
    "df2 = df[(df[col].fillna('').str.contains('Universi'))|(df[col].fillna('').str.contains('College'))]\n",
    "df2a = explode(df2,col,delimiter='|')\n",
    "df2a = df2a.drop_duplicates(subset=['affiliation','month','issued'], keep='first')\n",
    "df2a[col] = df2a[col].str.split(',',expand=True)[0]\n",
    "df3 = df2a[(df2a[col].fillna('').str.contains('Universi'))|(df2a[col].fillna('').str.contains('College'))]\n",
    "dfg = df3[[col,'issued']].groupby(col).count()\n",
    "dfg.columns = ['count']\n",
    "dfg = dfg.sort_values(by=['count'],ascending=False)\n",
    "dfg = dfg.head(n)\n",
    "print(str(len(df)) + ' records in original dataframe.')\n",
    "print(str(len(df3)) + ' records in expanded/filtered dataframe.')\n",
    "unilist = dfg.index.tolist()\n",
    "display(HTML(dfg.head().to_html()))\n",
    "\n",
    "cols = [col] + ['month','issued']\n",
    "df_selected = df3[df3[col].isin(unilist)]\n",
    "dfg = df_selected[[col,'month','issued']].groupby([col,'month']).count()\n",
    "dfg.columns = ['records']\n",
    "dfg = dfg.sort_values(by=['month'],ascending=False)\n",
    "print(str(len(df)) + ' records in original dataframe.')\n",
    "print(str(len(df3)) + ' records in expanded/filtered dataframe.')\n",
    "dfg = dfg.reset_index()\n",
    "df = dfg[['month','affiliation','records']].copy()\n",
    "display(HTML(df.head().to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once I had the extracted, filtered and summarized by month rollup for the top universities, I used a variation on the same rolling total function to build that dataframe. This totaler also fills in missing months for Universities with zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>affiliation</th>\n",
       "      <th>records</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>All</td>\n",
       "      <td>All</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>2019-07</td>\n",
       "      <td>All</td>\n",
       "      <td>15</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>2019-06</td>\n",
       "      <td>All</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>2019-04</td>\n",
       "      <td>All</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>2019-03</td>\n",
       "      <td>All</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       month affiliation  records  total\n",
       "576      All         All       43     43\n",
       "561  2019-07         All       15     43\n",
       "571  2019-06         All        1     28\n",
       "568  2019-04         All        6     27\n",
       "567  2019-03         All        2     21"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find aggregated counts for each month from all resource categories\n",
    "dfg = df.groupby(['month']).agg({'records': ['sum']}).reset_index()\n",
    "dfg.columns = ['month','records']\n",
    "dfg['affiliation'] = 'All'\n",
    "dfg = dfg[['month','affiliation','records']]\n",
    "df = pd.concat([df, dfg], ignore_index=True)\n",
    "\n",
    "# Aggregate running totals for each category\n",
    "month_list = list(set(df['month'].tolist()))\n",
    "types_list = df[['affiliation']].drop_duplicates().to_dict('records')\n",
    "df2 = pd.DataFrame(columns=['month', 'affiliation', 'records', 'total'])\n",
    "for types in types_list:\n",
    "    for month in month_list:\n",
    "        total = df[(df['month'] <= month) & \n",
    "                  (df['affiliation'] == types['affiliation'])]['records'].sum()\n",
    "        dfp2 = df[(df['month'] == month) & \n",
    "                  (df['affiliation'] == types['affiliation'])].copy()\n",
    "        if len(dfp2) == 0:\n",
    "            dfp2 = pd.DataFrame([[month, types['affiliation'], 0]], \n",
    "                                columns=['month', 'affiliation', 'records'])\n",
    "        dfp2['total'] = total\n",
    "        # Concatenated back to working Dataframe\n",
    "        df2 = pd.concat([df2, dfp2], ignore_index=True)\n",
    "df2 = df2.astype({\"records\": int,\"total\": int})\n",
    "\n",
    "# Find aggregated counts for all months from each categories\n",
    "dfg = df2.groupby(['affiliation']).agg({'records': ['sum'],\n",
    "                                        'total': ['max']}).reset_index()\n",
    "dfg.columns = ['affiliation','records','total']\n",
    "dfg['month'] = 'All'\n",
    "dfg = dfg[['month','affiliation','records','total']]\n",
    "# Concatenated back to working Dataframe\n",
    "df2 = pd.concat([df2, dfg], ignore_index=True)\n",
    "df2 = df2.sort_values(by='total', ascending=False)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the running totals were complete, I needed to geocode the locations of the Universities, with the goal of creating a map visualization in the final tool. This required the customized functions for OSM and Google's geocoder APIs. The overall function loops through the unique locations and checks OSM first. If OSM doesn't return a result it checks Google, since Google is rate limited up to a certain number of requests a day (without paying)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking OSM geocoder for Department of Computer- Al - MuthannaUniversity. (10/10)\n",
      "Checking Google geocoder for Department of Computer- Al - MuthannaUniversity.\n",
      "{'name': 'Department of Computer- Al - MuthannaUniversity.', 'rawloc': Location(3043 H.M. Comer 245, 7th Ave, Tuscaloosa, AL 35487, United States, (33.2154879, -87.5444806, 0.0)), 'latitude': 33.2154879, 'longitude': -87.5444806, 'country': 'US', 'city': 'Tuscaloosa'}\n",
      "Geocoding complete\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>rawloc</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Assam Don Bosco University</td>\n",
       "      <td>(Assam, Vallée-du-Ntem, SU, Cameroun, (2.33656...</td>\n",
       "      <td>2.336569</td>\n",
       "      <td>10.882855</td>\n",
       "      <td>CM</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Taif University</td>\n",
       "      <td>(Umm Al Qura University / Girls Campus, At Tai...</td>\n",
       "      <td>21.346149</td>\n",
       "      <td>39.928786</td>\n",
       "      <td>SA</td>\n",
       "      <td>مكة</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Universitas Ekasakti</td>\n",
       "      <td>(Jl. Veteran No.26B, Purus, Kec. Padang Bar., ...</td>\n",
       "      <td>-0.934607</td>\n",
       "      <td>100.354880</td>\n",
       "      <td>ID</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cardiff University</td>\n",
       "      <td>(Cardiff University, Park Place, Castle, Cardi...</td>\n",
       "      <td>51.487996</td>\n",
       "      <td>-3.179697</td>\n",
       "      <td>GB</td>\n",
       "      <td>Cardiff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Postgraduate Student Of Brawijaya University.</td>\n",
       "      <td>(Jl. Veteran Malang, Ketawanggede, Kec. Lowokw...</td>\n",
       "      <td>-7.952504</td>\n",
       "      <td>112.613860</td>\n",
       "      <td>ID</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            name  \\\n",
       "0                     Assam Don Bosco University   \n",
       "1                                Taif University   \n",
       "2                           Universitas Ekasakti   \n",
       "3                             Cardiff University   \n",
       "4  Postgraduate Student Of Brawijaya University.   \n",
       "\n",
       "                                              rawloc   latitude   longitude  \\\n",
       "0  (Assam, Vallée-du-Ntem, SU, Cameroun, (2.33656...   2.336569   10.882855   \n",
       "1  (Umm Al Qura University / Girls Campus, At Tai...  21.346149   39.928786   \n",
       "2  (Jl. Veteran No.26B, Purus, Kec. Padang Bar., ...  -0.934607  100.354880   \n",
       "3  (Cardiff University, Park Place, Castle, Cardi...  51.487996   -3.179697   \n",
       "4  (Jl. Veteran Malang, Ketawanggede, Kec. Lowokw...  -7.952504  112.613860   \n",
       "\n",
       "  country     city  \n",
       "0      CM           \n",
       "1      SA      مكة  \n",
       "2      ID           \n",
       "3      GB  Cardiff  \n",
       "4      ID           "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Open Street Map (OSM) Nominatim and Google Geocoders\n",
    "geolocator = Nominatim(user_agent=ua)\n",
    "geolocator2 = GoogleV3(api_key=gkey)\n",
    "\n",
    "# Extract location field to deduplicated list\n",
    "loc_names = list(set(dfg['affiliation'].to_list()))\n",
    "if 'All' in loc_names:\n",
    "    loc_names.remove('All')\n",
    "\n",
    "if demo == True:\n",
    "    loc_names = loc_names[:10]\n",
    "    \n",
    "# Loop through locations to find coordinates\n",
    "locs_clean = []\n",
    "result_count = 0\n",
    "for loc_name in loc_names:\n",
    "    result_count += 1\n",
    "    time.sleep(3)\n",
    "    clear_output()\n",
    "    print('Checking OSM geocoder for ' + loc_name + ' (' + str(result_count) + '/' + str(len(loc_names)) + ')')\n",
    "    # Search OSM API for location\n",
    "    try:\n",
    "        loc_clean = osm_geocode(loc_name, geolocator)\n",
    "    except:\n",
    "        try:\n",
    "            time.sleep(10)\n",
    "            loc_clean = osm_geocode(loc_name, geolocator)\n",
    "        except:\n",
    "            print('Checking Google geocoder for ' + loc_name)\n",
    "            loc_clean = google_geocode(loc_name, geolocator2)\n",
    "    # If OSM returns no coordinates, search Google geocode API\n",
    "    if loc_clean['latitude'] == '':\n",
    "        print('Checking Google geocoder for ' + loc_name)\n",
    "        loc_clean = google_geocode(loc_name, geolocator2)\n",
    "    # Append geocoder result dictionary to results list\n",
    "    locs_clean += [loc_clean]\n",
    "    print(loc_clean)\n",
    "print('Geocoding complete')\n",
    "\n",
    "# Convert results dictionary list to Pandas dataframe\n",
    "dfmap = pd.DataFrame(locs_clean)\n",
    "dfmap = dfmap[dfmap.longitude != ''].copy()\n",
    "dfmap.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to verify the results of the geocoding, I dropped the coordinates from the new geocoded dataframe into a Folium map. Folium uses the same Leaflet HTML/JS embedded map that we'll use later on for the actual visualization product, so this is a helpful preview for how it will look.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><iframe src=\"data:text/html;charset=utf-8;base64,<!DOCTYPE html>
<head>    
    <meta http-equiv="content-type" content="text/html; charset=UTF-8" />
    <script>L_PREFER_CANVAS=false; L_NO_TOUCH=false; L_DISABLE_3D=false;</script>
    <script src="https://cdn.jsdelivr.net/npm/leaflet@1.4.0/dist/leaflet.js"></script>
    <script src="https://code.jquery.com/jquery-1.12.4.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js"></script>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/leaflet@1.4.0/dist/leaflet.css"/>
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css"/>
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap-theme.min.css"/>
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css"/>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css"/>
    <link rel="stylesheet" href="https://rawcdn.githack.com/python-visualization/folium/master/folium/templates/leaflet.awesome.rotate.css"/>
    <style>html, body {width: 100%;height: 100%;margin: 0;padding: 0;}</style>
    <style>#map {position:absolute;top:0;bottom:0;right:0;left:0;}</style>
    
    <meta name="viewport" content="width=device-width,
        initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />
    <style>#map_7369d70fe6db4fcda8b25ad776418bc0 {
        position: relative;
        width: 100.0%;
        height: 100.0%;
        left: 0.0%;
        top: 0.0%;
        }
    </style>
</head>
<body>    
    
    <div class="folium-map" id="map_7369d70fe6db4fcda8b25ad776418bc0" ></div>
</body>
<script>    
    
    
        var bounds = null;
    

    var map_7369d70fe6db4fcda8b25ad776418bc0 = L.map(
        'map_7369d70fe6db4fcda8b25ad776418bc0', {
        center: [2.3365686, 10.8828549],
        zoom: 10,
        maxBounds: bounds,
        layers: [],
        worldCopyJump: false,
        crs: L.CRS.EPSG3857,
        zoomControl: true,
        });


    
    var tile_layer_ebfdb8885e8c423ab95f20c0fe9714e2 = L.tileLayer(
        'https://cartodb-basemaps-{s}.global.ssl.fastly.net/light_all/{z}/{x}/{y}.png',
        {
        "attribution": null,
        "detectRetina": false,
        "maxNativeZoom": 18,
        "maxZoom": 18,
        "minZoom": 0,
        "noWrap": false,
        "opacity": 1,
        "subdomains": "abc",
        "tms": false
}).addTo(map_7369d70fe6db4fcda8b25ad776418bc0);
    
            var circle_marker_02cd3b882c2e4534adbde4b72af6aa80 = L.circleMarker(
                [2.3365686, 10.8828549],
                {
  "bubblingMouseEvents": true,
  "color": "#3388ff",
  "dashArray": null,
  "dashOffset": null,
  "fill": true,
  "fillColor": "#3db7e4",
  "fillOpacity": 0.2,
  "fillRule": "evenodd",
  "lineCap": "round",
  "lineJoin": "round",
  "opacity": 1.0,
  "radius": 5,
  "stroke": true,
  "weight": 3
}
                )
                .addTo(map_7369d70fe6db4fcda8b25ad776418bc0);
            
    
        circle_marker_02cd3b882c2e4534adbde4b72af6aa80.bindTooltip(
            `<div>`
            + `<b>Location:</b>Assam Don Bosco University<br><b>City:</b><br><b>Country:</b>CM` + `</div>`,
            {"sticky": true}
        );
        
    
            var circle_marker_e453539bfa0449cdb633cced9b364559 = L.circleMarker(
                [21.34614905, 39.928785666573],
                {
  "bubblingMouseEvents": true,
  "color": "#3388ff",
  "dashArray": null,
  "dashOffset": null,
  "fill": true,
  "fillColor": "#3db7e4",
  "fillOpacity": 0.2,
  "fillRule": "evenodd",
  "lineCap": "round",
  "lineJoin": "round",
  "opacity": 1.0,
  "radius": 5,
  "stroke": true,
  "weight": 3
}
                )
                .addTo(map_7369d70fe6db4fcda8b25ad776418bc0);
            
    
        circle_marker_e453539bfa0449cdb633cced9b364559.bindTooltip(
            `<div>`
            + `<b>Location:</b>Taif University<br><b>City:</b>مكة<br><b>Country:</b>SA` + `</div>`,
            {"sticky": true}
        );
        
    
            var circle_marker_69978d2656d044509c2ebe2b7c836395 = L.circleMarker(
                [-0.9346070999999999, 100.3548805],
                {
  "bubblingMouseEvents": true,
  "color": "#3388ff",
  "dashArray": null,
  "dashOffset": null,
  "fill": true,
  "fillColor": "#3db7e4",
  "fillOpacity": 0.2,
  "fillRule": "evenodd",
  "lineCap": "round",
  "lineJoin": "round",
  "opacity": 1.0,
  "radius": 5,
  "stroke": true,
  "weight": 3
}
                )
                .addTo(map_7369d70fe6db4fcda8b25ad776418bc0);
            
    
        circle_marker_69978d2656d044509c2ebe2b7c836395.bindTooltip(
            `<div>`
            + `<b>Location:</b>Universitas Ekasakti<br><b>City:</b><br><b>Country:</b>ID` + `</div>`,
            {"sticky": true}
        );
        
    
            var circle_marker_bb1e3597b25340df98fcf909ef012c61 = L.circleMarker(
                [51.4879961, -3.17969747443907],
                {
  "bubblingMouseEvents": true,
  "color": "#3388ff",
  "dashArray": null,
  "dashOffset": null,
  "fill": true,
  "fillColor": "#3db7e4",
  "fillOpacity": 0.2,
  "fillRule": "evenodd",
  "lineCap": "round",
  "lineJoin": "round",
  "opacity": 1.0,
  "radius": 5,
  "stroke": true,
  "weight": 3
}
                )
                .addTo(map_7369d70fe6db4fcda8b25ad776418bc0);
            
    
        circle_marker_bb1e3597b25340df98fcf909ef012c61.bindTooltip(
            `<div>`
            + `<b>Location:</b>Cardiff University<br><b>City:</b>Cardiff<br><b>Country:</b>GB` + `</div>`,
            {"sticky": true}
        );
        
    
            var circle_marker_db10a6400c434fa283ffe94cc915ad38 = L.circleMarker(
                [-7.952504299999999, 112.6138604],
                {
  "bubblingMouseEvents": true,
  "color": "#3388ff",
  "dashArray": null,
  "dashOffset": null,
  "fill": true,
  "fillColor": "#3db7e4",
  "fillOpacity": 0.2,
  "fillRule": "evenodd",
  "lineCap": "round",
  "lineJoin": "round",
  "opacity": 1.0,
  "radius": 5,
  "stroke": true,
  "weight": 3
}
                )
                .addTo(map_7369d70fe6db4fcda8b25ad776418bc0);
            
    
        circle_marker_db10a6400c434fa283ffe94cc915ad38.bindTooltip(
            `<div>`
            + `<b>Location:</b>Postgraduate Student Of Brawijaya University.<br><b>City:</b><br><b>Country:</b>ID` + `</div>`,
            {"sticky": true}
        );
        
    
            var circle_marker_a51b109f070f4326992f23845401e169 = L.circleMarker(
                [60.17103775, 24.9491506306407],
                {
  "bubblingMouseEvents": true,
  "color": "#3388ff",
  "dashArray": null,
  "dashOffset": null,
  "fill": true,
  "fillColor": "#3db7e4",
  "fillOpacity": 0.2,
  "fillRule": "evenodd",
  "lineCap": "round",
  "lineJoin": "round",
  "opacity": 1.0,
  "radius": 5,
  "stroke": true,
  "weight": 3
}
                )
                .addTo(map_7369d70fe6db4fcda8b25ad776418bc0);
            
    
        circle_marker_a51b109f070f4326992f23845401e169.bindTooltip(
            `<div>`
            + `<b>Location:</b>University of Helsinki<br><b>City:</b>Helsinki<br><b>Country:</b>FI` + `</div>`,
            {"sticky": true}
        );
        
    
            var circle_marker_8511d0d12c5d4eb5bde7ce522b09a46a = L.circleMarker(
                [52.9387428, -1.20029569274574],
                {
  "bubblingMouseEvents": true,
  "color": "#3388ff",
  "dashArray": null,
  "dashOffset": null,
  "fill": true,
  "fillColor": "#3db7e4",
  "fillOpacity": 0.2,
  "fillRule": "evenodd",
  "lineCap": "round",
  "lineJoin": "round",
  "opacity": 1.0,
  "radius": 5,
  "stroke": true,
  "weight": 3
}
                )
                .addTo(map_7369d70fe6db4fcda8b25ad776418bc0);
            
    
        circle_marker_8511d0d12c5d4eb5bde7ce522b09a46a.bindTooltip(
            `<div>`
            + `<b>Location:</b>University of Nottingham<br><b>City:</b>City of Nottingham<br><b>Country:</b>GB` + `</div>`,
            {"sticky": true}
        );
        
    
            var circle_marker_3822105a1411449d8730aea52d6d5816 = L.circleMarker(
                [38.2899482, 21.7886469],
                {
  "bubblingMouseEvents": true,
  "color": "#3388ff",
  "dashArray": null,
  "dashOffset": null,
  "fill": true,
  "fillColor": "#3db7e4",
  "fillOpacity": 0.2,
  "fillRule": "evenodd",
  "lineCap": "round",
  "lineJoin": "round",
  "opacity": 1.0,
  "radius": 5,
  "stroke": true,
  "weight": 3
}
                )
                .addTo(map_7369d70fe6db4fcda8b25ad776418bc0);
            
    
        circle_marker_3822105a1411449d8730aea52d6d5816.bindTooltip(
            `<div>`
            + `<b>Location:</b>University of Patras<br><b>City:</b>Πάτρα<br><b>Country:</b>GR` + `</div>`,
            {"sticky": true}
        );
        
    
            var circle_marker_46189c756e8446e6a4161a890930817a = L.circleMarker(
                [56.631457, 47.889107],
                {
  "bubblingMouseEvents": true,
  "color": "#3388ff",
  "dashArray": null,
  "dashOffset": null,
  "fill": true,
  "fillColor": "#3db7e4",
  "fillOpacity": 0.2,
  "fillRule": "evenodd",
  "lineCap": "round",
  "lineJoin": "round",
  "opacity": 1.0,
  "radius": 5,
  "stroke": true,
  "weight": 3
}
                )
                .addTo(map_7369d70fe6db4fcda8b25ad776418bc0);
            
    
        circle_marker_46189c756e8446e6a4161a890930817a.bindTooltip(
            `<div>`
            + `<b>Location:</b>Federal State Budgetary Educational Institution of Higher Education "Mari State University"<br><b>City:</b>Yoshkar-Ola<br><b>Country:</b>RU` + `</div>`,
            {"sticky": true}
        );
        
    
            var circle_marker_0cb444968618417e89a428c92e2f66af = L.circleMarker(
                [33.2154879, -87.5444806],
                {
  "bubblingMouseEvents": true,
  "color": "#3388ff",
  "dashArray": null,
  "dashOffset": null,
  "fill": true,
  "fillColor": "#3db7e4",
  "fillOpacity": 0.2,
  "fillRule": "evenodd",
  "lineCap": "round",
  "lineJoin": "round",
  "opacity": 1.0,
  "radius": 5,
  "stroke": true,
  "weight": 3
}
                )
                .addTo(map_7369d70fe6db4fcda8b25ad776418bc0);
            
    
        circle_marker_0cb444968618417e89a428c92e2f66af.bindTooltip(
            `<div>`
            + `<b>Location:</b>Department of Computer- Al - MuthannaUniversity.<br><b>City:</b>Tuscaloosa<br><b>Country:</b>US` + `</div>`,
            {"sticky": true}
        );
        
    
                

                map_7369d70fe6db4fcda8b25ad776418bc0.fitBounds(
                    [[-7.952504299999999, -87.5444806], [60.17103775, 112.6138604]],
                    {}
                    );
            
</script>\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x200b1310048>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create folium map of geocoded locations as circles\n",
    "m = folium.Map(location=[dfmap['latitude'][0], dfmap['longitude'][0]], tiles=\"CartoDB positron\")\n",
    "for index, row in dfmap.iterrows():\n",
    "    folium.CircleMarker([row['latitude'], row['longitude']],\n",
    "                        radius=5,\n",
    "                        tooltip='<b>Location:</b>' + row['name'] + \n",
    "                        '<br><b>City:</b>' + row['city'] + \n",
    "                        '<br><b>Country:</b>' + row['country'],\n",
    "                        fill_color=\"#3db7e4\",\n",
    "                       ).add_to(m)\n",
    "\n",
    "# Fit map to locations\n",
    "m.fit_bounds([\n",
    "    [dfmap.latitude.min(),dfmap.longitude.min()],\n",
    "    [dfmap.latitude.max(), dfmap.longitude.max()]\n",
    "]);\n",
    "\n",
    "# Show map\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the map looked good, I merged the locations back into my summarization dataframe and created a new set of JSON and CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "612\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>affiliation</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>records</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>2019-04</td>\n",
       "      <td>Universitas Ekasakti</td>\n",
       "      <td></td>\n",
       "      <td>ID</td>\n",
       "      <td>-0.934607</td>\n",
       "      <td>100.355</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>All</td>\n",
       "      <td>Universitas Ekasakti</td>\n",
       "      <td></td>\n",
       "      <td>ID</td>\n",
       "      <td>-0.934607</td>\n",
       "      <td>100.355</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>All</td>\n",
       "      <td>Taif University</td>\n",
       "      <td>مكة</td>\n",
       "      <td>SA</td>\n",
       "      <td>21.3461</td>\n",
       "      <td>39.9288</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>2019-07</td>\n",
       "      <td>Department of Computer- Al - MuthannaUniversity.</td>\n",
       "      <td>Tuscaloosa</td>\n",
       "      <td>US</td>\n",
       "      <td>33.2155</td>\n",
       "      <td>-87.5445</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>All</td>\n",
       "      <td>Department of Computer- Al - MuthannaUniversity.</td>\n",
       "      <td>Tuscaloosa</td>\n",
       "      <td>US</td>\n",
       "      <td>33.2155</td>\n",
       "      <td>-87.5445</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       month                                       affiliation        city  \\\n",
       "409  2019-04                              Universitas Ekasakti               \n",
       "411      All                              Universitas Ekasakti               \n",
       "358      All                                   Taif University         مكة   \n",
       "68   2019-07  Department of Computer- Al - MuthannaUniversity.  Tuscaloosa   \n",
       "69       All  Department of Computer- Al - MuthannaUniversity.  Tuscaloosa   \n",
       "\n",
       "    country  latitude longitude  records  total  \n",
       "409      ID -0.934607   100.355        3      3  \n",
       "411      ID -0.934607   100.355        3      3  \n",
       "358      SA   21.3461   39.9288        1      1  \n",
       "68       US   33.2155  -87.5445        1      1  \n",
       "69       US   33.2155  -87.5445        1      1  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfmerged = df2.set_index('affiliation').merge(dfmap.set_index('name'), how='left', left_on='affiliation', right_on='name', right_index = True, left_index = True).reset_index()\n",
    "dfmerged = dfmerged[['month','affiliation','city','country','latitude','longitude','records','total']].copy().fillna('')\n",
    "print(len(dfmerged))\n",
    "dfmerged = dfmerged[dfmerged['country'] != ''].copy()\n",
    "dfmerged.sort_values(['records'],ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='universities.json' target='_blank'>universities.json</a><br>"
      ],
      "text/plain": [
       "C:\\Users\\epcar\\universities.json"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfmerged.to_csv('universities.csv',index=False)\n",
    "FileLink('universities.csv')\n",
    "dfmerged.to_json('universities.json',orient='records')\n",
    "FileLink('universities.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Publication Subjects\n",
    "The last topic summarization I covered was publication subjects. Similar to affiliation, a record in Zenodo can have multiple subjects. Some subjects were split with semicolons in a single field on the page, and others were combined with | from my retrieval/parsing script, so I used the explode function twice with those two delimiters and then ran my summarization. Similarly I limited this to the top 100 topics as it wouldn't be feasible to create a clean visualization of more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creator</th>\n",
       "      <th>subject</th>\n",
       "      <th>month</th>\n",
       "      <th>issued</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ashraf Afifi</td>\n",
       "      <td>Chaos|Diffusion|Confusion|Encryptions|Henon map</td>\n",
       "      <td>2019-07</td>\n",
       "      <td>2019-07-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Салгириев Али Русланович|Баранов Андрей Владимирович|Костенко Юлия Витальевна</td>\n",
       "      <td>Россия|Северный Кавказ|политические элиты|политический процесс|структура|конфликты|напряженность|протест</td>\n",
       "      <td>2019-07</td>\n",
       "      <td>2019-07-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Жуков Олег Алексеевич</td>\n",
       "      <td>экспертные системы в электроэнергетике|экспертные системы|акронимический подход</td>\n",
       "      <td>2019-07</td>\n",
       "      <td>2019-07-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Prima Wulandari|Ridho Bayu Yefterson</td>\n",
       "      <td>Model Cooperative Learning|Think Talk Write|Aktivitas Belajar|Pembelajaran Sejarah</td>\n",
       "      <td>2019-07</td>\n",
       "      <td>2019-07-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Григорьева Елена Эдуардовна|Сентизова Надежда Руслановна</td>\n",
       "      <td>бюджетная обеспеченность|экономические зоны Якутии|асимметрия|дифференциация|методы|оценка</td>\n",
       "      <td>2019-07</td>\n",
       "      <td>2019-07-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148 records in original dataframe.\n",
      "454 records in exploded dataframe.\n",
      "454 records in expanded/filtered dataframe.\n",
      "148 records in original dataframe.\n",
      "454 records in expanded/filtered dataframe.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>subject</th>\n",
       "      <th>records</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-07</td>\n",
       "      <td>state formation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-07</td>\n",
       "      <td>proliferation index</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-07</td>\n",
       "      <td>uttar pradesh</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-07</td>\n",
       "      <td>pembelajaran sejarah</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-07</td>\n",
       "      <td>reduced basis</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     month               subject  records\n",
       "0  2019-07       state formation        1\n",
       "1  2019-07   proliferation index        1\n",
       "2  2019-07         uttar pradesh        1\n",
       "3  2019-07  pembelajaran sejarah        1\n",
       "4  2019-07         reduced basis        1"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query local database for all university publications\n",
    "engine = create_engine(sqlpath, echo=False)\n",
    "df = pd.read_sql_query(\n",
    "    'SELECT DISTINCT creator, subject, SUBSTR(issued,1,7) as month, SUBSTR(issued,1,10) as issued FROM zenodo \\\n",
    "    WHERE issued >= \"2001-01\" AND issued < \"2019-08\" AND subject <> \"\"\\\n",
    "    ORDER BY issued DESC;'\n",
    "    , engine).fillna('')\n",
    "\n",
    "print(len(df))\n",
    "display(HTML(df.head().to_html()))\n",
    "\n",
    "# Group by specified column and create sorted top n counts\n",
    "n = 100\n",
    "col = 'subject'\n",
    "df2 = df.copy()\n",
    "df2a = explode(df2,col,delimiter='; ').fillna('')\n",
    "df2 = df2a[df2a['subject'] != ''].copy()\n",
    "df2a = explode(df2,col,delimiter='|').fillna('')\n",
    "df2a = df2a[df2a['subject'] != ''].copy()\n",
    "df2a = df2a.drop_duplicates(subset=['subject','month','issued'], keep='first')\n",
    "df2a[col] = df2a[col].str.lower()\n",
    "df2a[col] = df2a[col].str.split(',',expand=True)[0]\n",
    "df2a = df2a[-df2a['subject'].str.contains(\"http|circum\")].copy()\n",
    "df3 = df2a.copy()\n",
    "dfg = df3[[col,'issued']].groupby(col).count()\n",
    "dfg.columns = ['count']\n",
    "dfg = dfg.sort_values(by=['count'],ascending=False)\n",
    "dfg = dfg.head(n)\n",
    "print(str(len(df)) + ' records in original dataframe.')\n",
    "print(str(len(df2a)) + ' records in exploded dataframe.')\n",
    "print(str(len(df3)) + ' records in expanded/filtered dataframe.')\n",
    "unilist = dfg.index.tolist()\n",
    "\n",
    "cols = [col] + ['month','issued']\n",
    "df_selected = df3[df3[col].isin(unilist)]\n",
    "dfg = df_selected[[col,'month','issued']].groupby([col,'month']).count()\n",
    "dfg.columns = ['records']\n",
    "dfg = dfg.sort_values(by=['month'],ascending=False)\n",
    "print(str(len(df)) + ' records in original dataframe.')\n",
    "print(str(len(df3)) + ' records in expanded/filtered dataframe.')\n",
    "dfg = dfg.reset_index()\n",
    "df = dfg[['month','subject','records']].copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This yielded another split/filtered by month summary which I then created a running total for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>subject</th>\n",
       "      <th>records</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2122</th>\n",
       "      <td>All</td>\n",
       "      <td>All</td>\n",
       "      <td>129</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2115</th>\n",
       "      <td>2019-07</td>\n",
       "      <td>All</td>\n",
       "      <td>39</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2110</th>\n",
       "      <td>2019-06</td>\n",
       "      <td>All</td>\n",
       "      <td>8</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2105</th>\n",
       "      <td>2019-05</td>\n",
       "      <td>All</td>\n",
       "      <td>10</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2119</th>\n",
       "      <td>2019-04</td>\n",
       "      <td>All</td>\n",
       "      <td>14</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        month subject  records  total\n",
       "2122      All     All      129    129\n",
       "2115  2019-07     All       39    129\n",
       "2110  2019-06     All        8     90\n",
       "2105  2019-05     All       10     82\n",
       "2119  2019-04     All       14     72"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find aggregated counts for each month from all resource categories\n",
    "dfg = df.groupby(['month']).agg({'records': ['sum']}).reset_index()\n",
    "dfg.columns = ['month','records']\n",
    "dfg['subject'] = 'All'\n",
    "dfg = dfg[['month','subject','records']]\n",
    "df = pd.concat([df, dfg], ignore_index=True)\n",
    "\n",
    "# Aggregate running totals for each category\n",
    "month_list = list(set(df['month'].tolist()))\n",
    "types_list = df[['subject']].drop_duplicates().to_dict('records')\n",
    "df2 = pd.DataFrame(columns=['month', 'subject', 'records', 'total'])\n",
    "for types in types_list:\n",
    "    for month in month_list:\n",
    "        total = df[(df['month'] <= month) & \n",
    "                  (df['subject'] == types['subject'])]['records'].sum()\n",
    "        dfp2 = df[(df['month'] == month) & \n",
    "                  (df['subject'] == types['subject'])].copy()\n",
    "        if len(dfp2) == 0:\n",
    "            dfp2 = pd.DataFrame([[month, types['subject'], 0]], \n",
    "                                columns=['month', 'subject', 'records'])\n",
    "        dfp2['total'] = total\n",
    "        # Concatenated back to working Dataframe\n",
    "        df2 = pd.concat([df2, dfp2], ignore_index=True)\n",
    "df2 = df2.astype({\"records\": int,\"total\": int})\n",
    "\n",
    "# Find aggregated counts for all months from each categories\n",
    "dfg = df2.groupby(['subject']).agg({'records': ['sum'],\n",
    "                                        'total': ['max']}).reset_index()\n",
    "dfg.columns = ['subject','records','total']\n",
    "dfg['month'] = 'All'\n",
    "dfg = dfg[['month','subject','records','total']]\n",
    "# Concatenated back to working Dataframe\n",
    "df2 = pd.concat([df2, dfg], ignore_index=True)\n",
    "df2 = df2.sort_values(by='total', ascending=False)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='subjects.json' target='_blank'>subjects.json</a><br>"
      ],
      "text/plain": [
       "C:\\Users\\epcar\\subjects.json"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.to_csv('subjects.csv',index=False)\n",
    "df2.to_json('subjects.json',orient='records')\n",
    "FileLink('subjects.csv')\n",
    "FileLink('subjects.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There were over 800,000 records on Zenodo in total for the time frame I looked at, including older publications uploaded to Zenodo, going back farther than 2000. However, for the final visualization, I limited the results to certain years with enough data to visualize, depending on the category."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "366px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
